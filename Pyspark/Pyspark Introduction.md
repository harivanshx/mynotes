# Agenda 

1. What is PySpark  
2. Spark Architecture  
3. What is RDD in Spark  
4. What is DAG and Lazy Evaluations  
5. Databricks Community Edition Setup  
6. Databricks Overview  
7. DataFrame PySpark  
8. PySpark DataFrame using JSON  
9. Select Function  
10. withColumn  
11. Filter in PySpark  
12. Drop and Drop Duplicate  
13. Sort and Order By  
14. Group By  
15. Joining  
16. Union and Union All  
17. fillna  
18. collect  
19. struct type  
20. Pivot and Unpivot  
21. UDF in PySpark  
22. DataFrame Transformation  
23. Create Temp View  
24. Windows Function using PySpark  
25. Date Format Function  
26. Partition By  
27. explode Function  
28. Cache and Persist  
29. PySpark Interview Questions  

---

**Projects:**  
- PySpark Project - 1  
- Databricks Project - 2





## What is spark

Spark is a general purpose in memory computation engine 

1. General Puspose

Data Cleaning
Query - Hive
ML operation - MAHOUT


Spark - Each and Every operation we can perform or do in spark itself 
- Data Cleaning
- SQL
- Spark mllib


2. Computation
Hadoop vs Spark
Hadoop Provide 3 components

	1. HDFS - Storage
	2. Resource Manager
	3. Map Reducer - Computation


3.  In memory 

- Ram 
- Spark does all computation in memory 
- spark is faster then map reduce

